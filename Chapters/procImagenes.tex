\myChapter{Técnicas de procesamiento de imágenes} \label{chap:ProcImagenes}
\minitoc\mtcskip
\vfill
\lettrine{A}{\relax} lo largo de esta Tesis Doctoral se utilizan conceptos y métodos de \textsc{Procesamiento de Imágenes} que deben ser explicados más a fondo para una mejor comprensión de los algoritmos y métodos desarrollados. En este capí­tulo se hace una revisión de las principales técnicas de extracción de bordes en imágenes. También se muestra un estudio actualizado de los métodos que otros investigadores han utilizado para eliminar o minimizar la dependencia de los cambios de iluminación en diversos algoritmos de procesamiento de imágenes. La gran mayorí­a de estos métodos se desarrollaron principalmente para abordar el problema de las sombras en las imágenes, cuya presencia (en distintos escenarios) suele afectar negativamente a los algoritmos de procesamiento.\\
\noindent Este capí­tulo comienza con la descripción del modelo de formación de imágenes. Tras esto, se describe el modelo \textsc{LIP}, que se servirá como base matemática para la construcción de los algoritmos que se propondrán en esta Tesis.  Posteriormente, se describen algunos modelos de ruido de generación natural. A continuación, se muestran diversos métodos para la extracción de los contornos de los objetos, basados en operadores que utilizan el gradiente y/o el laplaciano de las imágenes, obtenidos utilizando el operador matemático \emph{convolución}.
\vfill
\section{Modelos de formación de imágenes}
\lettrine{E}{l} modelo multiplicativo de formación de imágenes \citep{oppenheim68,gonzalez02} afirma que las imágenes captadas son una superposición de longitudes de onda de diferentes frecuencias que responden, en una primera aproximación, a las componentes de la iluminación de la imagen y a la luz reflejada \citep{erhardt-ferron00} (o transmitida, dependiendo del tipo de imagen considerada) \graffito{Las imágenes que observamos son una mezcla multiplicativa de iluminación y reflectancia.} por los objetos presentes en la escena que se está observando. A estas dos componentes se les denomina respectivamente, \emph{iluminación} y \emph{reflectancia} o \emph{transmitancia}, dependiendo del tipo de imagen que se esté considerando (ver cuadro \textsc{¿Reflectancia o Transmitancia?} al pie de página). Este modelo sigue la siguiente formulación:
\begin{equation}
f(x,y) = i(x,y)\cdot r(x,y),
\end{equation}
\noindent donde $f(x,y)$ es el valor de la función de intensidad recibida por el observador asociado al punto $(x,y)$ del sistema de referencia del propio observador. Este valor se define mediante la multiplicación de dos factores: la \emph{iluminación} ($i(x,y)$) de la imagen que se recibe en dicho punto y la componente de \emph{reflectancia}, $r(x,y)$, que representa el valor de la proyección del objeto asociado a la posición $(x,y)$.
\subsection{Filtrado homomórfico}\label{sec:filtradoHomomorfico}
Habitualmente, se desea poder procesar imágenes evitando la influencia de la \emph{iluminación}, ya que ésta puede no ser uniforme, es decir, puede haber sombras, brillos, etc., que podrí­an desvirtuar el contenido real (los objetos presentes) de la escena observada. Esto significa que se desea descartar toda la información de la componente de \emph{iluminación} y trabajar únicamente con la componente de \emph{reflectancia}; sin embargo, las dos componentes se entremezclan entre sí­ espacialmente de tal manera que no es posible separarlas directamente mediante operadores lineales.\\
\vfill
{\hspace{-10em}\begin{tabular*}{\paperwidth}{DC}
¿Reflectancia \mbox{o Transmitancia}? & Las imágenes generadas mediante transmisión de luz son llamadas imágenes de \textsc{Transmitancia}, entre las que se encuentran por ejemplo las de microscopí­a. En éstas existe un foco luminoso cuyo haz de luz traspasa el objeto observado, que no es totalmente opaco, y el receptor recibe información visual de la cantidad de luz que los objetos observados permiten traspasar. \newline En contraposición, existen las llamadas imágenes de \textsc{Reflectancia}, que son las imágenes captadas por los observadores debidas a la reflexión de la luz de un foco sobre las superficies de objetos opacos y no especulares. Lo que el observador recibe en este caso es la cantidad de luz que los objetos reflejan. En general, todas las fotografí­as realizadas con cámaras de exposición son de este tipo.\\
\end{tabular*}}
\clearpage
\noindent Utilizando el espacio transformado de Fourier se puede mostrar que la \emph{iluminación} afecta a todas las frecuencias, ya que la transformada de Fourier de la multiplicación de las dos componentes no es \mbox{separable \citep{gonzalez02}}, es decir:
\begin{equation}
\Fourier{}\Big\{f(x,y)\Big\}\neq\Fourier{}\Big\{i(x,y)\Big\}\cdot \Fourier{}\Big\{r(x,y)\Big\},
\end{equation}
\noindent donde la transformada de Fourier viene indicada por $\Fourier{}\left\{\cdot\right\}$.\\
\noindent La no separabilidad de estas dos componentes impide la eliminación directa de la \emph{iluminación}. Sin embargo, se ha podido demostrar \citep{oppenheim68,oppenheim69} que:
\begin{equation}
z(x,y) = \ln \left(f(x,y)\right) = \ln \left(i(x,y)\right) + \ln \left(r(x,y)\right)
\end{equation}
\noindent Por lo tanto,
\begin{equation}
\Fourier{}\Big\{z(x,y)\Big\}=\Fourier{}\Big\{\ln \left(f(x,y)\right)\Big\}=\Fourier{}\Big\{\ln \left(i(x,y)\right)\Big\} + \Fourier{}\Big\{\ln \left(r(x,y)\right)\Big\} \label{eq:fourierMHIP}
\end{equation}
\noindent La ecuación \ref{eq:fourierMHIP} muestra la base del modelo \definicion{\textsc{MHIP}}{Del inglés, \textsc{Multiplicative Homomorphic Image Processing}, procesamiento de imágenes multiplicativas homomórficas}. La teorí­a de probabilidades \citep{gallego01} afirma que si tanto $\ln \left(i(x,y)\right)$ como $\ln \left(r(x,y)\right)$ son dos funciones estadí­sticamente independientes, el histograma del logaritmo de la combinación de ambas se obtiene mediante la convolución de los histogramas del logaritmo de cada una de las componentes. En la mayorí­a de los casos, \graffito{Las superficies Lambertianas reflejan la luz en todas direcciones, de manera independiente al ángulo de incidencia.} no se suele poder acceder a la fuente de \emph{iluminación}, por lo que hay que hacer una estimación de dicha componente. Para un conjunto de objetos con superficies Lambertianas \citep{jahne02} se puede suponer \apriori que la \emph{iluminación} varí­a suavemente. De hecho, la \emph{iluminación} es una componente que se localiza principalmente en las bajas frecuencias. Por tanto, se puede afirmar que para un entorno de tamaño reducido es prácticamente constante. Por ello, se puede aceptar como aproximación de primer orden que:
\begin{equation}
LPF\bigg[\Fourier{}\Big\{\ln\left(f(x,y)\right)\Big\}\bigg] \approx \Fourier{}\Big\{\ln\left(i(x,y)\right)\Big\}, \label{eq:aproxIluminacion}
\end{equation}
\noindent donde $LPF\left[\cdot\right]$ (siglas en inglés de \textsc{Low Pass Filter}, \emph{Filtro Paso Baja}) es una función que calcula el filtrado paso baja en frecuencia de una función dada. Con lo que para pequeños entornos de un punto, se puede asumir que:
\begin{equation}
f(x,y) = i\cdot r(x,y)
\end{equation}
Por lo que, sustituyendo (\ref{eq:aproxIluminacion}) en (\ref{eq:fourierMHIP}), se tiene que:
\begin{equation}
\Fourier{}\Big\{\ln \left(f(x,y)\right)\Big\} \approx LPF\bigg[\Fourier{}\Big\{\ln\left(f(x,y)\right)\Big\}\bigg] + \Fourier{}\Big\{\ln \left(r(x,y)\right)\Big\} \label{eq:logImagenMHIP}
\end{equation}
\noindent De (\ref{eq:logImagenMHIP}) se puede calcular $\ln \left(f(x,y)\right)$ puesto que se tiene la imagen completa. Además se puede estimar $\ln\left(i\right)$ mediante algún filtro paso baja (ya que como se ha indicado anteriormente, $\ln\left(i\right)$ se encuentra principalmente en las bajas frecuencias), por lo que finalmente se puede calcular la componente de \emph{reflectancia}:
\begin{equation}
\Fourier{}\Big\{\ln \left(r(x,y)\right)\Big\} \approx \Fourier{}\Big\{\ln \left(f(x,y)\right)\Big\} - LPF\bigg[\Fourier{}\Big\{\ln\left(f(x,y)\right)\Big\}\bigg]\label{eq:logFourierReflectance1}
\end{equation}
\noindent También se puede calcular mediante:
\begin{equation}
\Fourier{}\Big\{\ln \left(r(x,y)\right)\Big\} \approx \ln \left( \frac{ \Fourier{}\Big\{ f(x,y) \Big\} }{ LPF \bigg[ \Fourier{}\Big\{ f(x,y) \Big\} \bigg] } \right) \label{eq:logFourierReflectance2}
\end{equation}
\noindent Para reducir el coste computacional, habitualmente se utiliza (\ref{eq:logFourierReflectance1}), ya que es más sencilla de calcular que (\ref{eq:logFourierReflectance2}). Por este mismo motivo, de manera general no se realiza el cálculo de la transformada de Fourier, por lo que la fórmula final queda:
\begin{equation}
\ln \left(r(x,y)\right) \approx \ln \left(f(x,y)\right) - \ln\left(i\right)\label{eq:logReflectance1}
\end{equation}
\noindent donde $\ln\left(i\right)$ representa la \emph{iluminación} de un determinado entorno de un punto, obtenido como el filtro paso baja del logaritmo de la imagen.\\
\noindent En la Sec. \ref{sec:introLIP} se describe otro modelo de construcción de imágenes, que permite un manejo más eficiente (en el sentido de robustez) de las componentes de \emph{iluminación} y de \emph{reflectancia} (o \emph{transmitancia}) que el modelo \textsc{MHIP}.
\section{Descripción del modelo LIP}\label{sec:introLIP}
\lettrine{F}{ue} a finales de la década de los 80 y a lo largo de la década de los 90, cuando \person{Jourlin} y \person{Pinoli} \citep{jourlin87,jourlin88} expusieron un nuevo paradigma para el procesamiento de imágenes por proyección de luz (como es el caso de imágenes de microscopí­a). El estudio y posterior desarrollo de \definicion{LIP}{Del inglés, \textsc{Logarithmic Image Processing}, Procesamiento de Imágenes Logarí­tmicas.} se realizó para obtener una respuesta satisfactoria a la pregunta ``\emph{¿Cómo evita el sistema visual humano el problema del resultado fuera de rango al sumar dos imágenes?}''. Pretendí­an dar solución a un problema tan habitual en los sistemas de procesamiento de imágenes digitales, como es el del desbordamiento del rango en la adición de dos imágenes o en el ajuste multiplicativo por una constante. Posteriormente, otros autores hicieron grandes contribuciones a este paradigma a lo largo de toda la década de los 90.\\
\noindent La aplicación de operadores tradicionales a imágenes digitales de tipo natural (obtenidas tanto por proyección o transmisión de la luz, como por su reflejo en los objetos de la escena) no es una solución matemáticamente robusta ni tiene una justificación fí­sica o psico--fí­sica \citep{pinoli97b}. Los autores originales del paradigma \textsc{LIP} describieron operadores matemáticos que, además de realizar la combinación y la amplificación (desde el punto de vista del procesamiento) de imágenes de microscopí­a, también eran consistentes con la naturaleza fí­sica de las imágenes que se trataban.\\
En este ámbito, los autores comprobaron que al superponer en el microscopio dos platinas con muestras, el observador puede ver la composición de ambas. Es decir, que al sumar dos imágenes el observador obtiene una imagen dentro del rango visible. También, pudieron observar que aunque aumentasen la iluminación incidente en la platina, la imagen observada continuaba siendo visible. Por tanto, no es posible obtener ninguna combinación de muestras y de iluminación que proporcione un resultado que no esté dentro del rango visible por el ojo humano (es decir, combinando imágenes en el rango visible no es posible obtener una imagen ultravioleta o infrarroja). Tomando como punto de partida estas observaciones, los autores definieron el brillo de un punto de una imagen en el modelo \textsc{LIP}, como la cantidad de luz que pasa por un \emph{filtro lumí­nico} con una determinada \emph{función de absorción} (o el grado de opacidad que presenta dicho filtro lumí­nico en un punto).
\subsection{Nomenclaturas y rangos}\label{sec:ranges}
Antes de explicar el planteamiento matemático de \textsc{LIP}, se especificarán los rangos de valores y la notación de las diferentes variables y funciones que se utilizarán en este trabajo.\\
\noindent Para empezar, cualquier escalar se notará mediante letras griegas minúsculas ($\alpha \in \mathbb{R}$). Los vectores de escalares reales se notarán con letras minúsculas en negrita, como $\vec{a}$, $\vec{b}$. Como excepción a la regla anterior, notaremos como $M$ al valor máximo del rango permitido en función de la profundidad de bits de la paleta utilizada. Dicho valor máximo es inalcanzable. El mí­nimo valor (también inalcanzable) permitido en las imágenes es el $0$. Estas dos afirmaciones anteriores se justificarán de manera más extensa en la Sec. \ref{sec:leyesLIP:Inversion}. De manera breve, la elección de estos extremos encuentra su justificación en el mundo real, en el que la oscuridad absoluta (sin incidencia de ningún fotón) o la iluminación máxima absoluta (inyección de infinitos fotones) en condiciones naturales no puede ocurrir. En el caso de su aparición en imágenes digitales, se produce debido al proceso de captura, cuantización y digitalización de la imagen real. Para solucionar la presencia de estos valores límite no admisibles por \textsc{LIP}, se puede realizar un redondeo al valor válido más cercano sin pérdida de generalidad.\\
\noindent Aunque originalmente \textsc{LIP} fue diseñado para utilizarse con imágenes, al tener una base matemática consistente y robusta, permite su generalización y uso a otros elementos, sin que estos tengan que representar necesariamente una imagen. Los autores denominan a estos elementos como \emph{funciones de tonalidades de gris}. Éstas se nombrarán con letras minúsculas, por ejemplo, $f$ y $g$, con rangos $f,g \in (0,M) \subseteq \mathbb{R}$. De manera adicional, las imágenes habitualmente utilizadas con \textsc{LIP} suelen tener una paleta de tonalidades de gris, que en esta Tesis Doctoral se notarán con letras mayúsculas, $I$, $J$, etc. El rango \graffito{Si trabajamos con imágenes de 8 bits de profundidad, el máximo valor será 255, con lo que, $M = 256$.} de estas imágenes será $I \in (0,M) \subseteq \mathbb{N}$, o de manera equivalente, $I \in \left[1,M-1\right] \subseteq \mathbb{N}$. En general, todo lo que se afirme para las \emph{funciones de tonalidades de gris,} también es cierto para las \emph{imágenes con paleta de tonalidades de gris}, de manera que se pueden utilizar ambos términos de manera indistinta. Los filtros bidimensionales también se notarán con letras mayúsculas, por ejemplo, $F$.\\
\noindent Para poder utilizar el paradigma \textsc{LIP}, es necesario utilizar imágenes adaptadas a dicho modelo, no pudiéndose utilizar de manera directa las imágenes con la paleta habitual. Cada valor de la paleta de estas imágenes se denomina \emph{tono de gris de la función de tonalidades de gris} (a partir de ahora se denominarán simplemente \emph{tonos de gris}, por brevedad) y se representarán con un acento circunflejo sobre la misma letra, por ejemplo, $\widehat{f} = M -  f$, con $\widehat{f} \in (0,M) \subseteq \mathbb{R}$. Para poder aprovechar la potencialidad matemática que brindan las estructuras algebraicas de los espacios vectoriales, se ha expandido matemáticamente el rango de trabajo de los \emph{tonos de gris} a $\widehat{f} = (-\infty,M) \subseteq \mathbb{R}$. Hay que tener en cuenta que sólo los \emph{tonos de gris} positivos tienen una asociación fí­sica con las imágenes reales, mientras que los \emph{tonos de gris} pertenecientes al rango $(-\infty, 0)$ tienen sólo un significado matemático y no real.\\
\noindent Como se mostrará en la Sec. \ref{sec:matematicasLIP}, \textsc{LIP} permite trabajar de dos maneras diferentes, unas de las cuales incluye una función isomórfica de transformación de los elementos. Así­ pues, los \emph{tonos de gris} transformados utilizando la función isomórfica de \textsc{LIP}, por abreviar a partir de ahora, \emph{tonos de gris \textsc{LIP}}, se notarán con sus respectivas letras con una virgulilla ($\ \tilde{}\ $) sobre la misma; por ejemplo, $\tilde{f} \in \mathbb{R} $.
\subsection{Bases matemáticas de LIP}\label{sec:matematicasLIP}
Los autores propusieron una estructura que, además de resolver la problemática de las operaciones fuera de rango, cumple muchas leyes fí­sicas, psico--fí­sicas y de percepción visual humana. Existen dos ``mecanismos'' para aplicar \textsc{LIP} a cualquier técnica de procesamiento de imágenes:
\begin{itemize}
\item Usar imágenes ``originales'' y un conjunto de operadores ``modificados''.
\item Usar imágenes ``transformadas'' y los operadores ``tradicionales''.
\end{itemize}
A continuación se mostrará una breve descripción de cada uno de estos dos mecanismos indicados previamente.
\subsubsection{Método Directo: Imágenes ``Originales'' y operadores ``modificados''}
Esta primera opción, que se ha dado en llamar \emph{directa} por el uso directo de las imágenes originales, se genera mediante un espacio vectorial, que está definido por:
\begin{itemize}
\item Un conjunto de imágenes con valores de \emph{tonos de gris}, notado como $\mathbb{G}^{+}$, que son imágenes ``usuales'' a las que se les ha aplicado una inversión de la escala:
\begin{equation}
\widehat{f} = M - f
\end{equation}
\item Una operación suma modificada, $\LIPplus$, definida como:
\begin{equation}
\widehat{f} \LIPplus \widehat{g} = \widehat{f}+\widehat{g} -\frac{\widehat{f}\cdot \widehat{g}}{M} \label{eq:LIPplus}
\end{equation}
\begin{SCfigure}[][!t]
\includegraphics[width=21pc]{gfx/LennaPeppers}\caption[Imágenes de ejemplo:\\\emph{Muestra las dos imágenes de ejemplo utilizadas para mostrar el funcionamiento de \textsc{LIP}.}]{Muestra de las dos imágenes de ejemplo.}\label{fig:ejemplos}
\end{SCfigure}
\begin{SCfigure}[][!t]
\includegraphics[width=21pc]{gfx/sumaLennaPeppers}\caption[Suma de dos imágenes: \emph{Comparación de la operación suma de dos imágenes entre la suma estándar y la suma \textsc{LIP}.}]{Suma de dos imágenes. Izquierda, suma estándar. Derecha, suma LIP. En rojo, todos los pí­xeles que se encuentran fuera de rango.}\label{fig:suma2Img}
\end{SCfigure}
\begin{SCfigure}[][!t]
\includegraphics[width=21pc]{gfx/mult4Lenna}\caption[Multiplicación escalar por 4: \emph{Comparación de la operación multiplicación escalar de una imagen por el valor 4, utilizando la multiplicación estándar y la multiplicación \textsc{LIP}.}]{Multiplicación escalar de una imágen por 4. Izquierda, multiplicación estándar. Derecha, multiplicación LIP. En rojo, todos los pí­xeles que se encuentran fuera de rango.}\label{fig:mult4LIP}
\end{SCfigure}\\[-0.5em]
\noindent Este operador garantiza que la suma de dos \emph{tonos de gris} cualesquiera será, a su vez, otro \emph{tono de gris} (y por tanto, se puede asegurar que el resultado se mantendrá dentro de rango). La demostración matemática de esta propiedad se muestra en el Apéndice \ref{chap:apendiceA}. Visualmente, se puede apreciar el resultado de esta operación en la Fig. \ref{fig:suma2Img}, en la que se muestra la suma de las dos imágenes de la Fig. \ref{fig:ejemplos}, tanto en su versión estándar como en su versión \textsc{LIP}. Como se muestra en la imagen de la izquierda de la Fig. \ref{fig:suma2Img}, existen muchos pí­xeles cuyo valor está fuera de rango (señalados en rojo), mientras que en la imagen de la derecha de la Fig. \ref{fig:suma2Img}, todos los pí­xeles contienen valores dentro de rango.
\item Un operador que implementa una multiplicación modificada de un \emph{tono de gris} por un escalar, $\LIPtimes$, definida por:
\begin{equation}
\alpha \LIPtimes \widehat{f}=M-M\cdot\left(1-\frac{\widehat{f}}{M}\right)^\alpha \label{eq:LIPtimes}
\end{equation}

\noindent Este operador garantiza que la multiplicación de un escalar por un \emph{tono de gris} es otro \emph{tono de gris}, es decir, el resultado está definido dentro del mismo rango de funcionamiento. La demostración de esta propiedad que presenta este operador se muestra en el Apéndice \ref{chap:apendiceB}. En la Fig. \ref{fig:mult4LIP} se muestra el resultado de la multiplicación de una de las imágenes de ejemplo de la Fig. \ref{fig:ejemplos} por $4$. En la multiplicación ``clásica'' (imagen izquierda de la Fig. \ref{fig:mult4LIP}), muchos pí­xeles de la imagen resultado se han desbordado y poseen valores fuera de rango, mientras que en la imagen resultado de la multiplicación \textsc{LIP} (imagen derecha de la Fig. \ref{fig:mult4LIP}) no hay ningún pí­xel con valor fuera de rango.
\item Finalmente, para extender la estructura algebraica que proporcionan $\left( \mathbb{G}^{+}, \LIPplus \ , \LIPtimes\right)$ a un espacio vectorial, se define de manera matemática el inverso de un \emph{tono de gris}, es decir, se define la parte negativa de $\mathbb{G}^{+}$, que se notará como $\mathbb{G}^{-}$. Se implementa un nuevo operador, $\LIPminus$ que define la resta de dos \emph{tonos de gris} como:
\begin{equation}
\widehat{f}\LIPminus \widehat{g} = M\cdot\frac{\widehat{f}-\widehat{g}}{M-\widehat{g}}\label{eq:lipminus}
\end{equation}
\noindent Partiendo de la idea expresada en la Sec. \ref{sec:introLIP} en la que, en el modelo \textsc{LIP}, el concepto de brillo de un punto de una imagen se define como la cantidad de luz que permite pasar un \emph{filtro lumí­nico} con un cierto grado de opacidad en dicho punto. Tomando el $0$ como el máximo nivel de iluminación posible (debido a la inversión del rango de los \emph{tonos de gris} indicado en el primer item), los \emph{tonos de gris} $\widehat{f} \in \mathbb{G}^{-}$ no tienen significado asociado en el mundo real. Puesto que una \emph{función de tonos de gris} negativa, significarí­a que hay un punto en el filtro que no sólo no es opaco y por tanto, no reduce la cantidad de luz incidente que permite pasar, sino que incrementa la iluminación del punto, pudiendo incluso ser más brillante que el valor máximo posible.
\end{itemize}
\noindent Gracias a este nuevo conjunto, $\mathbb{G} = \mathbb{G}^{+} \cup\ \mathbb{G}^{-}$, se puede definir un espacio vectorial compuesto por $\left(\mathbb{G}, \LIPplus \ , \LIPtimes \ , \LIPminus\right)$.\\
%\clearpage
\noindent Utilizando los operadores descritos, se han propuesto otros \citep{pinoli97,pinoli97b,deng98}. En este trabajo se utilizará el \mbox{\emph{Sumatorio--LIP}}, que fue diseñado partiendo de la \emph{Suma--LIP} especificada con anterioridad:
\begin{equation}
\LIPsum{i=1}{n} \widehat{f_i} = \widehat{f_1} \LIPplus \widehat{f_2} \LIPplus \ldots \LIPplus \widehat{f_n}
\end{equation}

\subsubsection{Método mediante la ``Transformada'': Imágenes ``Transformadas'' y operadores ``tradicionales''}
La segunda opción es transformar las imágenes, trabajar utilizando los operadores ``tradicionales'', y finalmente, restaurar la imagen resultante al espacio original mediante la inversa de la transformada inicial.\\
La transformada se realiza mediante una función llamada \emph{transformada isomórfica} que se define como:
\begin{equation}
\tilde{f}=\varphi(\widehat{f}) = -M\cdot\ln\left(1-\frac{\widehat{f}}{M}\right) \label{eq:isomorTransf}
\end{equation}
La inversa de la función de transformación se denomina \emph{transformada isomórfica inversa} y se define como:
\begin{equation}
\widehat{f}=\varphi^{-1}(\tilde{f}) = M\cdot\left(1-e^{-\frac{\tilde{f}}{M}}\right) \label{eq:inverseIsomorTransf}
\end{equation}
\subsection{Relación con otros modelos logarí­tmicos}
Existen otros paradigmas, definidos con anterioridad a \textsc{LIP}, que resuelven el problema de las operaciones fuera de rango, como por ejemplo el modelo \textsc{MHIP} \citep{oppenheim68,oppenheim69}, descrito brevemente con anterioridad en la Sec. \ref{sec:filtradoHomomorfico}, o \definicion[0.1em]{\textsc{LRIP}}{Del inglés, \textsc{Log--Ratio Image Processing}, procesamiento de imágenes de razón logarítmica.} \citep{shvayster87,shvayster83}. Estos tres paradigmas han sido comparados \citep{pinoli97} desde tres puntos de vista diferentes: según la estructura matemática sobre la que se han construido, según la relación de cada modelo con las leyes fí­sicas o psico--fí­sicas que los justifican, y finalmente, en función del coste computacional de su desarrollo.\\
El estudio muestra que los tres modelos poseen una base matemática de álgebra lineal. En ese aspecto, tanto \textsc{MHIP} como \textsc{LRIP}, poseen estructuras algebraicas basadas únicamente en espacios vectoriales, con ordenación mediante la estructura de norma. Por otra parte, \textsc{LIP} está basado en una estructura algebraica de \emph{cono lineal con topologí­a ordenada positiva} (ver \textsc{cono lineal positivo} al pie de página), al cual se le proporciona el opuesto, obteniéndose un espacio vectorial completo. Esta estructura algebraica tan robusta proporciona un significado matemático a los conceptos fí­sicos usados en las imágenes. Por tanto, se pueden definir los operadores siguiendo el sentido de una estructura de orden, que desde un punto de vista estrictamente algebraico produce operadores mucho más robustos que los obtenidos seguiendo una estructura de norma, tal y como ocurre en los modelos \textsc{MHIP} y \textsc{LRIP}.\\
\noindent En el citado artí­culo \citep{pinoli97}, se demuestra que \textsc{LRIP} no sigue de forma rigurosa ninguna ley fí­sica o psico--fí­sica; y aunque \textsc{MHIP} sí­ está fundado en varias leyes fí­sicas y/o psico--fí­sicas, cumple un menor número de leyes que \textsc{LIP}. En la sección \ref{sec:leyesLIP} se muestra un resumen de las principales leyes fí­sicas y psico--fí­sicas que cumple el paradigma \textsc{LIP}. Por lo tanto, \textsc{LIP} se puede afirmar que es el modelo más general de los tres, puesto que está definido matemáticamente siguiendo estructuras más generales, permite su aplicación no sólo a imágenes sino a cualquier función matemática y cumple una mayor cantidad de leyes fí­sicas y psico--fí­sicas de construcción de imágenes.\\
\noindent Finalmente, con respecto al aspecto computacional, tanto \textsc{MHIP} como \textsc{LRIP} son dos modelos que trabajan utilizando ``transformadas'' (es decir, los algoritmos aplican inicialmente una función de transformación sobre la imagen, tras lo que realizan un procesamiento clásico sobre la imagen transformada y finalmente aplican la transformación inversa sobre la imagen resultante). Sin embargo, \textsc{LIP} es un modelo que permite una filosofí­a de trabajo tanto de tipo ``directo'' (los algoritmos clásicos\hfill se\hfill pueden\hfill programar\hfill usando\hfill operadores\hfill modificados 
\vfill
{\hspace{-3em} % página par {-9em}
%\setlength{\tabcolsep}{1em}
\begin{tabular*}{\paperwidth}{DC}
Cono Lineal & \em Se dice que un subconjunto $C$ de un espacio vectorial $V$ es un cono lineal, si y solo si $\lambda x \in C,\ \forall x \in C, \forall \lambda \in V$.\\
Cono Lineal con Topologí­a & \em Se dice que $C$ es un cono lineal con topologí­a, si $C$ es un cono lineal y si se cumple que $a \ge b$ entonces $a+c \ge b+c$, y también, $c+a \ge c+b$, $\forall a,b,c \in C$.\\
Cono Lineal Positivo & \em Sea $C$ un cono lineal con topologí­a. Se puede obtener el cono lineal con topologí­a ordenada positiva, denominado de manera abreviada, cono lineal positivo $C^{+} \subseteq C$, tomando el conjunto de valores $a \in C$ que cumplen que $a \ge 0$.\\
\end{tabular*}}
\clearpage
\noindent que proporcionan directamente una imagen resultante, sin necesidad de aplicar ninguna transformada) como de tipo ``transformada'', lo que hace que muchos algoritmos se puedan implementar utilizando, al menos, dos mecanismos diferentes.
\subsection{Leyes fí­sicas y psico--fí­sicas que cumple \textsc{LIP}}\label{sec:leyesLIP}
Como se ha indicado con anterioridad, además de tener una base algebraica robusta, \textsc{LIP} no es una mera invención matemática, sino que tiene un sustento en la forma en la que el sistema visual humano percibe las escenas. En el modelo \textsc{LIP}, el brillo de un punto de una imagen se ha demostrado que es la cantidad de luz que pasa por un filtro lumí­nico con una determinada función de absorción. Se ha demostrado \citep{pinoli97,pinoli97b} que \textsc{LIP} cumple una serie de leyes fí­sicas y de leyes psico--fí­sicas ampliamente aceptadas dentro de la comunidad cientí­fica, entre las que cabe destacar las siguientes:
\subsubsection{Inversión de escala de tonos de gris}\label{sec:leyesLIP:Inversion}
Los lí­mites del intervalo $(0,M)$ representan, respectivamente, el ``umbral superior'' (también conocido como \emph{lí­mite de deslumbramiento}) y el ``umbral inferior'' (o \emph{lí­mite de oscuridad total}). El \emph{lí­mite de deslumbramiento} se corresponde con el valor superior de iluminación que el ojo humano es capaz de soportar y distinguir, debido a la intensidad máxima con la que responden los fotorreceptores de la retina humana. Cualquier incremento de la intensidad lumínica por encima de dicho valor no se traduce en un aumento de la respuesta de los fotorreceptores, porque dichos fotorreceptores se encuentran funcionando al límite máximo. Por el contrario, al alcanzar el \emph{límite de oscuridad total}, el sistema visual humano mostraría una ausencia completa de respuesta. Sin embargo, este umbral de oscuridad es un límite teórico inalcanzable, puesto que está demostrado \citep{zuidema83,baylor84} que el ojo humano muestra sensibilidad a una baja cantidad de fotones. Esto se puede probar cerrando los ojos en una habitación oscura y notando como ``aparecen'' pequeños destellos en la imagen observada, similares al ruido gaussiano. Es decir, que el sistema visual humano proporciona repuesta ante una presencia ínfima de fotones, mostrando que incluso ante una oscuridad plena, el sistema visual humano tiene cierto nivel de sensibilidad, demostrando empíricamente que el \emph{límite de oscuridad total} no es alcanzable en condiciones naturales por el sistema visual humano.\\
La inversión de escala se justifica de dos maneras. La primera, en el ámbito de los procesos de formación de imágenes por luz transmitida, donde las \emph{funciones de tonos de gris} se deben tomar como filtros de transparencia, de manera que el valor $0$ se ha de tomar como \emph{transparencia total}, disminuyendo el grado de transparencia conforme aumenta el valor, hasta tomar el valor de \emph{opacidad total} ($M$). En segundo lugar, también tiene validez desde el punto de vista de la percepción visual humana. De hecho, se ha demostrado a través de experimentos psicofí­sicos \citep{baylor84} utilizando monos (que poseen un sistema visual con muchas semejanzas con el sistema visual humano) que en una ausencia completa de estímulos luminosos (simulando una teórica ``oscuridad plena''), la intensidad bio--eléctrica de la retina es constante a un valor no nulo y que el aumento de la iluminación en la recepción se traduce en una reducción de dicho nivel de intensidad bio--eléctrica y no en un aumento como cabrí­a esperar. Por tanto, para garantizar la inversión de escala, \textsc{LIP} hace uso de \emph{funciones de tono de gris} en lugar de imágenes en el rango habitual. Gracias a esta inversión, el modelo \textsc{LIP} trabaja de manera similar y consistente a como lo hace el sistema visual humano.
\subsubsection{Relación de los tonos de gris con la Intensidad Lumí­nica}
En el contexto de la percepción visual humana, una \emph{función de tono de gris} $\widehat{f}$ se relaciona con el valor de la función de intensidad de la luz incidente $F$ mediante:
\begin{equation}
\widehat{f}=M\left(1-\frac{F}{F_{\max}}\right) \label{eq:relacionTonoGrisconIntensidad}
\end{equation}
donde $F_{\max}$ es el \emph{umbral superior} o \emph{lí­mite de deslumbramiento} del sistema visual humano, anteriormente citado.\\
Utilizando \eqref{eq:relacionTonoGrisconIntensidad}, \textsc{LIP} permite relacionar un concepto físico, la función de intensidad de la luz incidente, $F$, con una definición propia del funcionamiento de \textsc{LIP}, como es la \emph{función de tono de gris}, $\widehat{f}$, que se corresponde con una función de intensidad de luz incidente valuada en el rango del intervalo real $(0,F_{\max}]$, donde $F_{\max}<M$. De hecho, la definición de un \emph{tono de gris} en el contexto de la percepción humana de la intensidad lumínica se puede considerar que es una función normalizada con inversión de escala.
\subsubsection{Saturación Lumí­nica}
Al contrario que otros paradigmas, que no están limitados en el rango de intensidades, \textsc{LIP} propone un rango limitado $(0,M)$, que es consistente con el principio de saturación lumí­nica del sistema visual humano, en el cual, más allá de un cierto lí­mite ($F_{\max}<M$), el ojo humano no es capaz de reconocer ningún aumento posterior en la cantidad de intensidad de luz incidente.
\subsubsection{Ley de Weber}
Desde mediados del siglo \textsc{XIX} se sabe que la respuesta del sistema visual humano a la intensidad lumí­nica no es lineal. Fue Weber el que expuso una ley en la que defendí­a que el sistema de detección visual humana depende del cociente de la división de los valores de intensidad lumínica más que de la diferencia entre los diversos valores de intensidad. De hecho, introdujo el concepto de ``\emph{diferencia de iluminación mí­nima distinguible}'', que es la cantidad de luz necesaria que hay que sumar a un campo de prueba con valor lumí­nico, $F$, para que sea visualmente apreciable la diferencia con otro campo de prueba fijo a un valor lumí­nico $F$. La ley de Weber se describe:
\begin{equation}
\frac{\Delta F}{F}=W
\end{equation}
donde $W$ es una constante, llamada \emph{Constante de Weber}.\\%Sean $F$ y $G$, dos valores de intensidad lumínica en un punto y, $\widehat{f}$ y $\widehat{g}$, sus tonos de gris asociados. La resta \textsc{LIP} de ambos, utilizando las Ec. \ref{eq:lipminus} y \ref{eq:relacionTonoGrisconIntensidad}, se define como:
% \begin{equation}
% \widehat{g}\LIPminus \widehat{f} = M\frac{\widehat{g}-\widehat{f}}{M-\widehat{f}}=M\frac{F-G}{F}
% \end{equation}
% Si se asume que $F$ y $G$ presentan intensidades lumínicas ``mí­nimamente distinguibles'', se puede aplicar $G = F+\Delta F$ y por tanto, la diferencia entre los tonos de gris asociados, denotada dicha diferencia como $\Delta \widehat{f}$ es:
% \begin{equation}
% \Delta \widehat{f} = \widehat{g}\LIPminus \widehat{f} = -M\frac{\Delta F}{F} = -M\cdot W
% \end{equation}

\noindent Está demostrado \cite{pinoli97b} que la operación resta \textsc{LIP} es consistente con la ley de Weber. Aunque esta ley ha sido muy criticada debido a que sólamente se cumple para valores de intensidad de luz superiores a un cierto nivel, y a que la constante de Weber sólo es válida dependiendo del tamaño del elemento a detectar. A pesar de todo ello, el modelo \textsc{LIP} es plenamente válido dentro del campo de modelización de la percepción visual humana, ya que en todas las situaciones donde sea cierta la ley de Weber, la resta \textsc{LIP} expresa correcta y coherentemente dicha ley.
\subsubsection{Ley de Fechner}
Unos años después que Weber, Fechner explicó la no--linealidad del sistema de percepción visual humano de la siguiente manera:
\begin{quote}
{\em Para producir pasos aritméticos incrementales en la sensación visual, la intensidad lumí­nica habrá de crecer geométricamente.}\end{quote}
\noindent Así­ pues, introdujo una relación entre la intensidad lumí­nica en un punto, $F$, tomado como estí­mulo de entrada y el brillo observado en dicho punto, $B$, que representa la sensación visual percibida por el ojo humano en dicho punto. Esta relación dió lugar a la \emph{Ley Discreta de Fechner}:
\begin{equation}
\Delta B = k\frac{\Delta F}{F}
\end{equation}
donde $\Delta F$ es el incremento de luz que produce un incremento de la sensación de brillo ($\Delta B$) y siendo $k$ una constante. La \emph{Ley Contí­nua de Fechner} se puede expresar como:
\begin{equation}
B= k'\ln\left(\frac{F}{F_{\min}}\right)
\end{equation}
donde $k'$ es una constante y $F_{\min}$ es el \emph{umbral de funcionamiento absoluto} del ojo humano que representa el valor de iluminación mínima a partir del cual comienzan a distinguirse cambios de iluminación y que se sabe que es muy cercano a la descripción fí­sica de oscuridad absoluta. La ley de Fechner se puede escribir también como:
\begin{equation}
B=k'\ln\left(\frac{F}{F_{\max}}\right)+k'\ln\left(\frac{F_{\max}}{F_{\min}}\right)\label{eq:fechner-continua}
\end{equation}
donde $F_{\max}$ es el \emph{umbral superior} o \emph{lí­mite de deslumbramiento} del sistema visual humano, anteriormente citado.\\
La resta \textsc{LIP} se muestra consistente con la \emph{Ley Discreta de Fechner} y con la \emph{Ley Contí­nua de Fechner}, puesto que aplicando el isomorfismo $\varphi$ del modelo \textsc{LIP} sobre \eqref{eq:fechner-continua} se obtiene \eqref{eq:fechner-LIP}, que demuestra la relación.
\begin{equation}
B=-\frac{k'}{M}\varphi(\widehat{f})+k'\ln\left(\frac{F_{\max}}{F_{\min}}\right)\label{eq:fechner-LIP}
\end{equation}
De hecho, la ley de Fechner fue uno de los primeros intentos de encontrar una escala lineal para el brillo o sensación de intensidad lumí­nica con las operaciones clásicas de suma y multiplicación, mientras que \textsc{LIP} define operaciones especí­ficas que trabajan directamente con la función de intensidad lumí­nica (estí­mulo de entrada).
\section{Modelos de ruido en imágenes}
\lettrine{L}{a} tecnologí­a de captación de imágenes por medios digitales está en un continuo avance. Los sensores admiten una mayor resolución y tienen un comportamiento cada vez más realí­stico. Sin embargo, la captación de imágenes no es precisa y hay una cierta probabilidad de introducir ruido en la imagen digitalizada. Este ruido se puede definir como la alteración apreciable en el valor de un pí­xel digital determinado con respecto al valor de intensidad asociado a la posición de dicho punto en la imagen real. Se ha estudiado ampliamente el ruido en las imágenes y se han propuesto diversos mecanismos para eliminar completamente (en los casos que sea posible) o, al menos, mitigar el efecto de dicho ruido.
\subsection{Ruido en imágenes}
Inicialmente, se debe precisar qué es lo que se entiende por ruido dentro del ámbito del \textsc{Procesamiento de Imágenes}. En \person{Bovik \etal} \citep{bovik00}, el ruido se define como \emph{una componente no deseada de la imagen digitalizada}. Sin embargo, esta definición es demasiado amplia y se puede concretar más indicando que:\\[1em]
\begin{tabular}{|A|}
\hline
Se define el \emph{ruido} en las imágenes como toda alteración no deseada en la imagen digitalizada que hace que ésta sea diferente de la imagen real original.\vspace{1em}\\
\hline
\end{tabular}\\[1em]
\noindent La mayorí­a de las veces dichas alteraciones son apreciables para el observador, pero otras son pequeñas modificaciones del valor digitalizado de los pí­xeles que apenas son detectables para el sistema visual humano. Desde el punto de vista matemático, las alteraciones sufridas por un pí­xel en particular pueden provenir de una modificación del valor del pí­xel ``real'' elevando o disminuyendo su valor linealmente. Así­ pues, una imagen con ruido se puede modelar \citep{gonzalez02} como:
\begin{equation}
g(x,y) = h(x,y) \ast f(x,y) + \eta(x,y),
\end{equation}
\noindent donde $f(x,y)$ es la imagen original, $g(x,y)$ es la imagen original alterada con ruido, $h(x,y)$ es una función de degradación que se aplica espacialmente mediante el operador convolución y $\eta(x,y)$ es un cierto ruido \emph{aditivo} no dependiente de la imagen original. La función $h(x,y)$ también es llamada ruido \emph{multiplicativo}.\\
\noindent Existen una variedad de modelos de ruido, la mayorí­a de ellos de tipo aditivo. A continuación se expondrán brevemente dos de los más habituales.
\paragraph{Ruido Gaussiano} \noindent El ruido aditivo más habitual es el gaussiano. Se utiliza para modelar el ruido termal y, bajo algunas ligeras restricciones asumibles, el ruido por conteo de fotones y el ruido por la granularidad de la pelí­cula fotográfica. Este tipo de ruido se basa en que la probabilidad de que un pí­xel se modifique se reduce siguiendo una distribución de probabilidad gaussiana conforme aumenta la diferencia entre el valor de la variación que sufre dicho pí­xel y el valor real del mismo. Es decir, la probabilidad de que un pí­xel no sufra variación alguna es elevada, y la probabilidad de que un pí­xel tenga una variación extrema es muy poco probable. La función de densidad que determina la probabilidad de ruido gaussiano univariado (con media $\mu$ y varianza $\sigma^2$) es:
\begin{equation}
P(x)=\frac{1}{\sigma\sqrt{2\pi}}\cdot e^{-\frac{(x-\mu)^2}{2\sigma^2}}
\end{equation}
\noindent donde $x$ puede tomar cualquier valor del interlvalo $(-\infty, \infty)$. Como esta definición puede provocar la obtención de valores negativos, aspecto no admisible en imágenes de intensidad, en la práctica el rango de valores de ruido gaussiano se limita a aproximadamente $\pm 3\sigma$, truncando aquellos valores que el ruido gaussiano pudiese llevar a obtener valores negativos \citep{bovik00}.\\
\noindent El ruido gaussiano es muy utilizado para modelar el comportamiento del ruido en las imágenes debido al propio proceso de captación de las mismas. Las imágenes son captadas por sensores \definicion{CCD}{Del inglés, \textsc{Charge--Coupled Device}, dispositivo de carga acoplada.} que miden la energí­a termal producida por el choque de los electrones incidentes en cada elemento del sensor. Los sensores \textsc{CCD} suponen que la mayorí­a de los electrones que captan provienen de la luz incidente, sin embargo, existen una cantidad de electrones provenientes del propio material del \textsc{CCD} que, por excitación termal, pueden incidir en el valor captado. Resumiedo, el ruido termal cumple tres caracterí­sticas: es el resultado de la vibración de una gran cantidad de electrones, la vibración de cada electrón es independiente de la de los demás y, finalmente, no existen electrones que provoquen una contribución significativa mayor que la de los demás. Estas tres condiciones (fácilmente asumibles) hacen que este ruido se pueda modelar como una distribución de probabilidad Gaussiana, gracias al Teorema del Lí­mite Central \citep{gallego01}. Es decir, el valor captado por cada sensor \textsc{CCD} se puede desviar ligeramente del valor real debido a la presencia de esos electrones excitados por vibración termal; es muy probable que la variación sea nula o muy cercana a cero y es muy poco probable que dicha variación sea muy grande.
\paragraph{Ruido de ``sal y pimienta''} \noindent Este tipo de ruido \graffito{El ruido de ``sal y pimienta'' presenta puntos blancos y negros de manera dispersa.} produce una degradación muy caracterí­stica en la imagen: sólo hay unos pocos pí­xeles ruidosos, pero la variación (el ruido) que presentan es extrema (tanto hacia el blanco como hacia el negro). Este tipo de ruido aparece tí­picamente en la transmisión de imágenes por canales digitales con muchas interferencias. En estos casos, cada bit se transmite de manera independiente a los demás, por lo que el cambio de valor de uno de los bits más significativos provoca que cambie completamente su valor debido a una mala decodificación.
\subsection{Emborronamiento de imágenes}
Por la propia naturaleza del ruido, en una primera aproximación se determina que éste se concentra en puntos más o menos aislados, en los que se produce un ``salto'' en los valores de la intensidad con respecto a los valores de los pí­xeles cercanos. Esto hace que el ruido modifique el espectro de la imagen en las altas frecuencias. Debido a esta caracterí­stica, la primera solución que se suele plantear ante la presencia de ruido es la aplicación de un operador de filtrado paso baja, para eliminar las componentes de altas frecuencias presentes en el ruido. Este filtro no deberí­a ser demasiado severo, puesto que podrí­a eliminar completamente la estructura de la imagen, ya que, como se ha comentado anteriormente, la \emph{reflectancia}, que contiene la estructura de los objetos, también se concentra principalmente en las altas frecuencias. En general, al aplicar un filtro paso baja se produce un cierto emborronamiento de las imágenes, mediante el cual se suele eliminar o mitigar el efecto local del ruido en la imagen, difuminando el efecto entre los pí­xeles de un entorno.\\
\noindent Para realizar el filtrado paso baja en el dominio espacial es habitual la utilización del operador convolución con máscaras más o menos extensas. Uno de los filtros paso baja más simples es el \emph{filtrado por la media} de entorno $X\times Y$, es decir, el valor de un pí­xel viene dado por la media de los valores del entorno de dicho pí­xel (incluyendo o no al pí­xel en consideración).\\
\noindent Existe otro conjunto de filtros paso baja más complejos, que son los basados en la distribución de probabilidad estadí­stica del ruido. El ruido es una alteración en la medida de un valor y está ampliamente aceptado que la variación en la medición de un valor sigue una distribución estadí­stica de tipo Gaussiana. También se ha estudiado \citep{canny86} que un pí­xel no es una variable estadí­stica independiente y que no todo el entorno de un pí­xel afecta por igual al valor del punto en consideración. Los pí­xeles más cercanos afectan o influyen más que los más lejanos. Si se supone que el ruido sigue una distribución estadí­stica de tipo Gaussiana, el filtrado de la imagen con una máscara Gaussiana permite que este filtrado afecte de manera controlada a los bordes reales de los objetos. El control de esta operación viene dado por la varianza de la distribución Gaussiana, que permite tener un filtro más amplio, más estrecho, etc., lo que permite modificar el conjunto de pí­xeles al que afecta la máscara Gaussiana. A esta operación se le suele denominar \emph{filtrado Gaussiano} de varianza $\sigma$.
\section{Extracción de bordes}
\lettrine{U}{na} de las operaciones fundamentales del procesamiento de imágenes es la detección de bordes, por lo que es un procedimiento muy común en el procesamiento de imágenes estáticas. Los bordes suelen coincidir con los lí­mites de los objetos presentes en las imágenes, aunque también pueden presentarse bordes internos a los objetos, en el fondo, o justo lo contrario, que no se muestre el borde de un objeto porque el cambio de la intensidad de la imagen en el borde no sea abrupto, sino muy gradual, y por lo tanto no se detecte. De manera genérica, existe una gran correlación entre los bordes fí­sicos de los objetos y los bordes representados en las imágenes. Sin embargo, existen casos en los que se pueden marcar como bordes en las imágenes pí­xeles que no corresponden con ningún objeto fí­sico, como es el caso de las sombras proyectadas.\\
\noindent De las tres grandes familias de operadores que extraen los bordes en las imágenes, Operadores basados en el Gradiente, Operadores basados en el Laplaciano y Operadores Morfológicos, a continuación sólo se introducen las dos primeras, ya que los Operadores Morfológicos no están relacionados con el trabajo desarollado en esta Tesis.
\vspace{-0.9em}\subsection{Filtros basados en el gradiente de la imagen}
\vspace{-0.5em}De manera genérica y, por simplificación, aplicado sobre imágenes en tonos de gris, se define un borde como la localización espacial de un cambio abrupto en valores de tonos de gris espacialmente cercanos. Esta afirmación se puede extender indicando que un \emph{borde se define como la localización espacial donde se da un máximo o un mí­nimo en la derivada de la función tono de gris, también llamado \textsc{gradiente} de la imagen}. En concreto, lo que se busca son los máximos en la función valor absoluto del gradiente de la imagen, es decir:
\begin{equation}
\left|\nabla f(x,y)\right| \geq T,
\end{equation}
\noindent donde $T$ representa el umbral de detección.\\

\noindent Una vez que se obtiene la imagen formada por aquellos pí­xeles cuyo gradiente es mayor que el umbral $T$, se suele aplicar un proceso de disminución o adelgazamiento de los máximos detectados, puesto que los extremos detectados suelen estar rodeados de valores altos que superan el umbral establecido y sólo interesan los valores máximos locales de cada entorno detectado en la dirección del gradiente.\\
\noindent En general, las aproximaciones al cálculo de la función gradiente en un espacio discreto, como es el de las imágenes digitales, se suele realizar mediante un par de filtros orientados ortogonalmente, $h_1(x,y)$ y $h_2(x,y)$. Estos se convolucionan de manera independiente sobre la imagen, de manera que la suma del resultado de ambos es la aproximación a la imagen gradiente:
\begin{equation}
\widehat{\nabla} f(x,y) = \left(f(x,y)\ast h_1(x,y)\right) \cdot \vec{u_1} + \left(f(x,y)\ast h_2(x,y)\right) \cdot \vec{u_2}
\end{equation}
\noindent donde $\vec{u_1}$ es un vector unitario en la dirección del filtro $h_1$ y $\vec{u_2}$ es un vector unitario en la dirección del filtro $h_2$.
\paragraph{Detectores Simples de Bordes Horizontales y Verticales} \noindent A veces se desea extraer únicamente bordes horizontales o verticales. Para ello, se convoluciona la imagen con filtros que responden sólo en dichas direcciones. Estos filtros pueden usar diferencias entre pí­xeles a distancia uno o diferencias centrales, que respectivamente son:
\begin{eqnarray}
h_1(x,y) =
\begin{bmatrix}
     0 & 0\\
    \circledtwochars{-1} & 1
\end{bmatrix} && h_2(x,y) =
\begin{bmatrix}
     1 & 0\\
    \circledtwochars{-1} & 0
\end{bmatrix}
\\
h_1(x,y) =
\begin{bmatrix}
     0 & 0 & 0\\
    -1 & \circled{0} & 1\\
     0 & 0 & 0
\end{bmatrix} && h_2(x,y) =
\begin{bmatrix}
     0 & 1 & 0\\
     0 & \circled{0} & 0\\
     0 &-1 & 0
\end{bmatrix}
\end{eqnarray}
\noindent Se ha resaltado la posición central $(x,y)$ sobre la que se aplica el filtro en la imagen.\\
\noindent Todos los filtros que se propongan han de sumar $0$ en sus componentes, ya que implementan una derivada y no deben dar una respuesta ante una constante.
\paragraph{Filtro de Roberts para bordes Diagonales}\noindent El filtro para la detección de bordes de Roberts \citep{roberts65} está indicado para la detección de bordes diagonales:
\begin{equation}
h_1(x,y) = \begin{bmatrix}
    0 & 1\\
    \circledtwochars{-1}&0
\end{bmatrix}
\qquad h_2(x,y) = \begin{bmatrix}
    1 & 0\\
    0&\circledtwochars{-1}
\end{bmatrix}
\end{equation}
\noindent Este operador presenta un par de problemas. El primero es que el punto de cruce de la diagonal $[-1\ 1]$ se localiza entre pí­xeles, es decir, que no coincide con ninguna posición real en la estructura en rejilla de los pí­xeles. Sin embargo, como es necesario asignar dicho punto de cruce a alguna localización, se producen errores de aproximación generalizados. El segundo problema que presenta este operador (y en general todos aquellos que usan sólo información de dos pí­xeles) es que su sensibilidad al ruido es bastante alta.
\paragraph{Filtro de Prewitt}\noindent Una posible solución para evitar el primero de los problemas que presenta el filtro anterior es diseñar los filtros en base a las diferencias centrales, para lo cual se utiliza habitualmente un entorno de $3\times3$ pí­xeles. Para evitar el segundo de los problemas se suele aplicar un suavizado, que lo que hace es incorporar más pí­xeles en el proceso de cómputo del valor del pí­xel central, dando el resultado en función de los pí­xeles de su entorno, no sólo de 2 pí­xeles.\\
\noindent Teniendo en cuenta esto, para obtener los filtros de Prewitt \citep{prewitt70} se definen dos funciones, $h_x(x)$ y $h_y(y)$, que dependen, respectivamente, sólo de $x$ e $y$. Mediante el producto escalar de estas dos funciones se obtienen unos filtros separables, ortogonales, y que además aplican suavizado al resultado:
\begin{equation}
h_y(y) = \begin{bmatrix}
1&\circled{1}&1
\end{bmatrix}'  \qquad h_x(x) = \begin{bmatrix}
-1&\circled{0}&1
\end{bmatrix}
\end{equation}
\begin{eqnarray}
h_1(x,y) &=& h_y(y)\cdot h_x(x) \nonumber \\
\begin{bmatrix}
    1\\
\circled{1}\\
    1
\end{bmatrix}\cdot
\begin{bmatrix}
-1&\circled{0}&1
\end{bmatrix} &=&
\begin{bmatrix}
-1&0&1\\
-1&\circled{0}&1\\
-1&0&1
\end{bmatrix}
\end{eqnarray}
\noindent Así­ pues, los filtros del operador de Prewitt son:
\begin{equation}
\begin{bmatrix}-1&0&1\\-1&\circled{0}&1\\-1&0&1\end{bmatrix} \qquad \begin{bmatrix}1&1&1\\0&\circled{0}&0\\-1&-1&-1\end{bmatrix}
\end{equation}
\paragraph{Filtro de Sobel}\noindent Propuesto por primera vez por \person{Irwin Sobel} \citep{sobel68,sobelPhD} en una charla dentro del Proyecto Stanford Artificial en 1968. Este operador se ha convertido en uno de los más utilizados tanto por la buena respuesta que ofrece como por su relativamente bajo coste computacional. Es una variante del operador de Prewitt, que utiliza $[1\ 2\ 1]$ en lugar de $[1\ 1\ 1]$, realizando un mejor suavizado. Por tanto, los filtros del operador de Sobel son:
\begin{equation}
\begin{bmatrix}-1&0&1\\-2&\circled{0}&2\\-1&0&1\end{bmatrix} \qquad \begin{bmatrix}1&2&1\\0&\circled{0}&0\\-1&-2&-1\end{bmatrix}\label{eq:mascarasSobelSTD}
\end{equation}
\paragraph{Filtro de Frei--Chen}\noindent El filtro de Prewitt tiene más sensibilidad a la detección de bordes horizontales y verticales que a los bordes diagonales, mientras que el filtro de Sobel tiene más sensibilidad a los bordes diagonales que a los horizontales y verticales. Esto es debido a que ambos filtros se han desarrollado sin tener en cuenta la compensación debida a la distancia, que es distinta entre los pí­xeles diagonales y los pí­xeles horizontales y verticales. Es decir, que tanto \emph{el filtro de Prewitt} como \emph{el filtro de Sobel} presentan \definicion{anisotropí­a}{Propiedad que se manifiesta de manera diferente según la dirección estudiada.}.\\
El filtro del operador de Frei--Chen \citep{frei77} es:
\begin{equation}
\begin{bmatrix}-1&0&1\\-\sqrt{2}&\circled{0}&\sqrt{2}\\-1&0&1\end{bmatrix} \qquad \begin{bmatrix}1&\sqrt{2}&1\\0&\circled{0}&0\\-1&-\sqrt{2}&-1\end{bmatrix}
\end{equation}
\noindent Este filtro, aunque no es totalmente isotrópico, puesto que no es rotacionalmente simétrico, introduce una anisotropí­a reducida y aceptable.
\paragraph{Filtro de Scharr}\noindent Existen muchos procesos que exigen filtros con muy alta isotropí­a, es decir, que se comporten de manera similar sin presentar mayor sensibilidad en la dirección de los patrones evaluados. \person{Scharr \etAl} \citep{scharr00} presentan un filtro que tiene un comportamiento invariante y optimizado ante la rotación.
\begin{equation}
\frac{1}{32}\cdot\begin{bmatrix}-3&0&3\\-10&\circled{0}&10\\-3&0&3\end{bmatrix} \qquad \frac{1}{32}\cdot\begin{bmatrix}3&10&3\\0&\circled{0}&0\\-3&-10&-3\end{bmatrix}
\end{equation}
\subsection{Filtros basados en el Laplaciano de la imagen}
El Laplaciano de una imagen $f(x,y)$ se define matemáticamente como:
\begin{equation}
\nabla^2 f(x,y)=\nabla \cdot \nabla f(x,y) = \frac{\partial^2 f(x,y)}{\partial x^2}+\frac{\partial^2 f(x,y)}{\partial y^2}
\end{equation}
\noindent Al aplicar la segunda derivada, los bordes de la imagen producirán ceros en esta función, por lo que una de las ventajas que proporciona es que produce bordes sin grosor, puesto que es el cero en sí­ el que proporciona un único punto de cruce, de manera que no es necesario aplicar un paso posterior de adelgazamiento de bordes. La función Laplaciana (en su versión de función continua) es isotrópica, puesto que no favorece ninguna dirección en particular. Además, los bordes que presenta son contornos cerrados, ya que, al no tener en cuenta la fuerza de los extremos, sino sólo el paso por cero, el más pequeño cambio gradual produce un paso por cero.\\
\noindent Sin embargo, el Laplaciano presenta algunos problemas:
\begin{itemize}
\item Produce la aparición de bordes falsos al detectarse pasos por cero en cambios de convexidad en la función de la imagen.
\item Presenta una alta sensibilidad a la presencia de errores, debido al uso de la segunda derivada, creando bordes falsos, al producirse cambios en regiones constantes, o modificando los bordes reales existentes.
\end{itemize}
\noindent El operador Laplaciano es un escalar, frente al operador gradiente que es un vector; por lo tanto, en lugar de un par de filtros ortogonales, es necesario un único filtro para obtener el Laplaciano.
\begin{equation}
\widehat{\nabla}^2 f(x,y) = f(x,y)\ast h(x,y) \label{eq:laplacianoGeneral}
\end{equation}
\noindent Para evitar el problema de la detección de los pasos por cero entre pí­xeles, en lugar de usar sólo 2 pí­xeles, se suele usar un entorno de 3 pí­xeles, de tal manera que se puede obtener un operador Laplaciano de manera simple de la siguiente forma:
\begin{eqnarray}
\frac{\partial f(x,y)}{\partial x} &\rightarrow & f_x(x,y) = f(x+1,y) - f(x,y) \label{eq:derivadaX}\\
\frac{\partial^2 f(x,y)}{\partial x^2} &\rightarrow & f_{xx}(x,y) = f(x,y) - f(x-1,y) \label{eq:derivadaX2bis}\\
\nonumber \\
\frac{\partial^2 f(x,y)}{\partial x^2} &\rightarrow & f_{xx}(x,y) =\nonumber\\
 &=& f(x+1,y) -2f(x,y) + f(x-1,y) =\nonumber\\
 &=& \begin{bmatrix}1&\circledtwochars{-2}&1\end{bmatrix} \label{eq:derivadaX2}
\end{eqnarray}
\noindent Actuando de manera análoga con $y$ se obtiene:
\begin{equation}
\frac{\partial^2 f(x,y)}{\partial y^2} \rightarrow f_{yy}(x,y) = \begin{bmatrix}1\\\circledtwochars{-2}\\1\end{bmatrix} \label{eq:derivadaY2}
\end{equation}
\noindent Al unificar \eqref{eq:laplacianoGeneral}, \eqref{eq:derivadaX2} y \eqref{eq:derivadaY2} (estas dos últimas extendidas a un tamaño de filtro de $3\times 3$), se puede calcular:
\begin{equation}
\widehat{\nabla}^2 f(x,y) = \begin{bmatrix}0&0&0\\1&\circledtwochars{-2}&1\\0&0&0\end{bmatrix}+\begin{bmatrix}0&1&0\\0&\circledtwochars{-2}&0\\0&1&0\end{bmatrix}=\begin{bmatrix}0&1&0\\1&\circledtwochars{-4}&1\\0&1&0\end{bmatrix}
\end{equation}
\noindent Mediante otras aproximaciones a la segunda derivada, es decir, proponiendo otras ecuaciones \eqref{eq:derivadaX} y \eqref{eq:derivadaX2bis} y utilizando este mismo método, se pueden construir otros filtros Laplacianos alternativos. Dos ejemplos de filtros Laplacianos distintos del anterior son:
\begin{equation}
\begin{bmatrix}1&1&1\\1&\circledtwochars{-8}&1\\1&1&1\end{bmatrix} \qquad \begin{bmatrix}-1&2&-1\\2&\circledtwochars{-4}&2\\-1&2&-1\end{bmatrix}
\end{equation}
\subsubsection{Laplaciano de Gaussianas (LoG)}
Aunque en una imagen pueden existir muchos bordes, el ojo humano es capaz de realizar segmentaciones automáticas y extraer sólo aquellos bordes que le interesan en función de la tarea que se está realizando; para detectar los objetos principales sólo se tienen en cuenta aquellos bordes más abruptos, mientras que para observar la textura de un objeto hay que tener en cuenta todos sus bordes y pliegues. Esta caracterí­stica ha sido altamente deseada por los cientí­ficos con el objetivo de obtener un detector de bordes ajustable según la sensibilidad escogida.\\
\noindent El operador Laplaciano de Gaussianas \citep{marr80}, \definicion{LoG}{Del inglés, \textsc{Laplacian of Gaussian}}, también conocido como operador de \emph{Marr--Hildreth}, es un operador que incorpora el concepto de control de sensibilidad. Se ha observado que la convolución de una imagen con un filtro Gaussiano produce un suavizado que limita la imagen resultante a un rango especí­fico de frecuencias, amortiguando el impacto de la presencia de ruido o de bordes débiles (y por tanto no deseados). Si sobre esta imagen filtrada se aplica el operador Laplaciano, se obtienen los pasos por cero en función del grado de sensibilidad que se desee, que es un parámetro controlable por la desviación tí­pica ($\sigma$) de la Gaussiana aplicada como filtro.\\
\noindent La Gaussiana presenta unas propiedades que facilitan su uso como filtro del detector de bordes:
\begin{itemize}
\item La Gaussiana es una función suave y claramente localizada tanto en el dominio espacial como en el dominio de las frecuencias. Esto permite un comportamiento de suavizado ante los errores a la vez que de precisión en la localización de los bordes reales.
\item La Gaussiana es separable, es decir, puede ser aplicada en cada dimensión de manera independiente, lo cual facilita una implementación eficiente.
\end{itemize}
\noindent El filtro Gaussiano en su forma contínua se expresa como:
\begin{equation}
g(x,y) = \frac{1}{\sigma\sqrt{2\pi}} e^{-\frac{x^2 + y^2}{2\sigma^2}} \label{eq:filtroGaussiano}
\end{equation}
\noindent Donde el parámetro $\sigma$ está inversamente relacionado con la frecuencia de corte.\\
\noindent Puesto que tanto el Laplaciano como la convolución son operadores lineales, aplicar un filtrado Gaussiano seguido de una derivación es equivalente a filtrar utilizando la derivada de una Gaussiana, tal y como se muestra en \eqref{eq:LoGbase}.
\begin{equation}
\nabla^2\left[f(x,y)\ast g(x,y)\right] = \left[\nabla^2 g(x,y)\right]\ast f(x,y)\label{eq:LoGbase}
\end{equation}
\noindent Al poder calcularse el Laplaciano de una Gaussiana de manera independiente de la imagen sobre la que se aplique, se puede crear previamente un conjunto de filtros para distintos valores de $\sigma$, utilizando la ecuación:
\begin{equation}
h(x,y) = \nabla^2 g(x,y) = \frac{x^2+y^2-2\sigma^2}{\sigma^4}\cdot e^{-\frac{x^2+y^2}{2\sigma^2}} \label{eq:LoG}
\end{equation}
\noindent El uso del operador de \emph{Marr--Hildreth} se justifica porque la función que representa \eqref{eq:LoG} posee un perfil muy similar al de la respuesta del campo espacial de visión biológica: una respuesta excitatoria circular simétrica rodeada de una banda de inhibición que se termina atenuando. La ecuación anterior se presenta en su forma contí­nua, pero para crear un filtro discreto hay que muestrear \eqref{eq:LoG}, usando un valor de $\sigma$ fijado de antemano. Dicho filtro es el que se utilizará posteriormente para convolucionar la imagen. Además, hay que escoger un tamaño suficientemente ancho para que no se produzcan efectos de truncamiento. Una regla habitualmente utilizada es fijar la anchura del filtro a un valor al menos 3 veces mayor que la anchura del pico central de excitación de la Gaussiana. Usualmente, el filtro resultante no suele ser pequeño, con lo cual es más eficiente realizar los cálculos en el dominio de las frecuencias, multiplicando las transformadas discretas de Fourier del filtro y de la imagen, y posteriormente realizarle la transformada inversa al resultado. Para acelerar el proceso de aplicación del filtro espacial, y puesto que la Gaussiana es una función separable, se aplica una convolución del filtro 1--D primero por filas y luego por columnas.
\subsection{Método de Canny para la extracción de bordes}
El detector de \person{Canny} \citep{canny86,gonzalez-tesis} utiliza la primera derivada (\emph{gradiente}) de las imágenes de una manera muy efectiva y suele ser considerado el detector de bordes más eficaz, aunque su complejidad y coste computacional es elevado. Está diseñado para cumplir los siguientes objetivos:
\begin{itemize}
\item \textsc{Baja tasa de error de detección}. Todos los contornos reales deben ser detectados.
\item \textsc{Alta precisión espacial de los bordes}. Los contornos detectados han de localizarse tan próximos como sea posible de la posición real.
\item \textsc{Respuesta única}. Un borde real debe pertenecer a un único contorno detectado.
\end{itemize}
\noindent Los pasos del algoritmo propuesto por \person{Canny} \citep{canny86} son:
\begin{aenumerate}
\item \textsl{Obtención del gradiente}
\begin{enumerate}
\item Suavizar la imagen, aplicando un filtrado Gaussiano \eqref{eq:filtroGaussiano}, de manera análoga a como se ha comentado para el Laplaciano de Gaussianas, pero de manera independiente: convolucionar la imagen sobre el eje $X$ con un filtro gaussiano y volver a convolucionar el resultado obtenido sobre el eje $Y$.
\item Aplicar sobre la imagen suavizada anteriormente una nueva convolución utilizando como filtro la derivada de \eqref{eq:filtroGaussiano} con respecto a los ejes $X$ e $Y$, respectivamente, obteniéndose dos imágenes convolucionadas.
\item Sobre las dos imágenes doblemente convolucionadas previamente, calcular la magnitud del gradiente y la dirección del mismo, utilizando las siguientes ecuaciones:
\begin{eqnarray}
\left|\widehat{\nabla}f(x,y)\right| &=& \sqrt{f^2_{\partial x}(x,y)+f^2_{\partial y}(x,y)}\\
\angle\ \widehat{\nabla}f(x,y) &=& \arctan\left(\frac{f_{\partial y}(x,y)}{f^2_{\partial x}(x,y)}\right)
\end{eqnarray}
\noindent donde $f_{\partial x}(x,y)$ es el punto $(x,y)$ de la imagen suavizada y derivada en $X$, $f_{\partial y}(x,y)$ es el punto $(x,y)$ de la imagen suavizada y derivada en $Y$, y $\left|\widehat{\nabla}f(x,y)\right|$ y $\angle\ \widehat{\nabla}f(xx,y)$ son, respectivamente, la magnitud del gradiente en el punto $(x,y)$ y el ángulo de dicho gradiente.
\end{enumerate}
\item \textsl{Eliminar puntos del gradiente que no sean máximos locales.}
\noindent Se determina que todo punto del gradiente es máximo local si su valor es mayor que el de los puntos vecinos en la dirección perpendicular al contorno (es decir, en la dirección del gradiente). Debido a la discretización del espacio, la magnitud del gradiente del punto se compara con el valor promedio del gradiente de aquellos puntos vecinos que están situados en la dirección del gradiente.
\item \textsl{Umbralización mediante histéresis.}
\noindent Tras los pasos previos hay que aplicar una \definicion{binarización}{Se define como una umbralización de una imagen para obtener una representación en blanco y negro de la misma.} en la cual se indica qué puntos pertenecen al contorno. Habitualmente, para esta tarea se ha utilizado un único umbral, sin embargo, se ha observado que esta opción no proporciona buenos resultados. Si el valor de un punto está cercano al valor umbral, es probable que otros puntos del contorno cercanos al mismo tengan un valor del gradiente menor y que, por lo tanto, se eliminen del contorno. Para evitar esto, se introducen dos umbrales: el de valor superior identifica aquellos puntos del contorno para los que no hay duda de su pertenencia, puesto que tienen un valor magnitud del gradiente bastante elevado, mientras que el umbral de valor inferior determina el valor mí­nimo por debajo del cual los puntos no son identificados como pertenecientes a ningún borde. Para aquellos puntos del gradiente que tengan un valor entre el umbral inferior y el superior, si están conectados con otro punto que pertenece al contorno, se identificarán como píxeles de los bordes.
\item \textsl{Sí­ntesis de caracterí­sticas de distintos niveles.} \label{it:CannySintesisCaracteristicas}
\noindent Si se aplican sobre una misma imagen distintos filtros gaussianos en los que lo único que se ha variado ha sido el parámetro $\sigma$, puede ocurrir que la localización de los bordes difiera un poco entre las distintas imágenes suavizadas. Aunque \apriori este comportamiento pueda parecer poco robusto, en la práctica es muy útil para la eliminación de los falsos contornos debidos al ruido, ya que es altamente improbable que un error aparezca en diversas imágenes suavizadas. Basándose en estos resultados, \person{Canny} propuso un mecanismo llamado de ``sí­ntesis de caracterí­sticas'' mediante el cual se unifican los distintos mapas de contornos obtenidos aplicando diferentes niveles de suavizado mediante un filtro Gaussiano. Esta unificación se realiza siguiendo una filosofí­a de ``fino a grueso'', localizando los contornos en un nivel más fino y buscando un posible pequeño desplazamiento en el nivel inmediatamente más grueso, para ir refinando la localización de dichos puntos del borde real.\\
\end{aenumerate}
\noindent Habitualmente este método no se presenta implementado en su totalidad. De hecho, el anterior paso \ref{it:CannySintesisCaracteristicas} no se suele realizar, puesto que los resultados que se obtienen utilizando el algoritmo hasta dicha etapa son de suficiente calidad y este paso es computacionalmente costoso.
\section{Conclusiones}
\lettrine{E}{n} este capí­tulo se han descrito las caracterí­sticas de bajo nivel más relevantes en el ámbito del procesamiento de imágenes. En particular, se ha descrito el modelo multiplicativo de formación de imágenes, que permite conceptualizar de manera más simple los elementos constituyentes que forman las imágenes. Gracias a este modelo, se puede eliminar la componente de \emph{iluminación} y trabajar únicamente con la componente de \emph{reflectancia} o \emph{transmitancia}.\\
\noindent Existen otros modelos de procesamiento de imágenes basados en la respuesta logarítmica de los modelos de formación de imágenes. En concreto, en este capítulo se ha descrito el modelo \textsc{LIP}. El cual cumple una gran cantidad de leyes físicas y psico--físicas, a la vez que está basado en una estructura algebraica robusta, lo que lo hace matemáticamente muy versátil. Este modelo sirve de base para el desarrollo de los operadores especiales que se proponen en esta Tesis Doctoral.\\
\noindent También se ha descrito qué se considera ruido en imágenes y se han expuesto los principales modelos. Otra parte importante de este capí­tulo se ha destinado a la descripción de los métodos de extracción de bordes. Se han expuesto diferentes mecanismos para la obtención de los contornos, basados en dos operadores matemáticos, el gradiente y el laplaciano. También, se ha mostrado la base matemática que subyace bajo todos estos conceptos elementales y operadores aplicados. Ésta se utilizará en capí­tulos posteriores para la construcción de nuevos operadores de imagen que permitan la obtención de contornos de objetos en escenas naturales con sombras o con iluminación no uniforme.\\
\noindent Los métodos de extracción de bordes son capaces de producir imágenes en las que se muestran los bordes relevantes. Se podrá determinar cúal es el mejor método de extracción de contornos mediante la evaluación de la calidad de las imágenes que generan dichos métodos. En el siguiente capí­tulo, se describirán diferentes mecanismos para la evaluación de la calidad de las imágenes procesadas. 